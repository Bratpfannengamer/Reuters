{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# %pip install tqdm\n",
    "# %pip install transformers\n",
    "#%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import My_Machine_Learning_Tools as mytools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('ModApte_train.csv')\n",
    "df_test=pd.read_csv('ModApte_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_list(df,column_name):\n",
    "    result=df[column_name].replace({' ':''},regex=True)\n",
    "    result.replace({'\\\\n':''},regex=True,inplace=True)\n",
    "    result.replace({'\\'\\'':'\\',\\''},regex=True,inplace=True)\n",
    "    return result.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9603 entries, 0 to 9602\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         8816 non-null   object\n",
      " 1   text_type    9603 non-null   object\n",
      " 2   topics       9603 non-null   object\n",
      " 3   lewis_split  9603 non-null   object\n",
      " 4   cgis_split   9603 non-null   object\n",
      " 5   old_id       9603 non-null   object\n",
      " 6   new_id       9603 non-null   object\n",
      " 7   places       9603 non-null   object\n",
      " 8   people       9603 non-null   object\n",
      " 9   orgs         9603 non-null   object\n",
      " 10  exchanges    9603 non-null   object\n",
      " 11  date         9603 non-null   object\n",
      " 12  title        9549 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 975.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text           object\n",
       "text_type      object\n",
       "topics         object\n",
       "lewis_split    object\n",
       "cgis_split     object\n",
       "old_id         object\n",
       "new_id         object\n",
       "places         object\n",
       "people         object\n",
       "orgs           object\n",
       "exchanges      object\n",
       "date           object\n",
       "title          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>topics</th>\n",
       "      <th>lewis_split</th>\n",
       "      <th>cgis_split</th>\n",
       "      <th>old_id</th>\n",
       "      <th>new_id</th>\n",
       "      <th>places</th>\n",
       "      <th>people</th>\n",
       "      <th>orgs</th>\n",
       "      <th>exchanges</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>\"NORM\"</td>\n",
       "      <td>['cocoa']</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"5544\"</td>\n",
       "      <td>\"1\"</td>\n",
       "      <td>['el-salvador' 'usa' 'uruguay']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-FEB-1987 15:01:01.79</td>\n",
       "      <td>BAHIA COCOA REVIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>\"NORM\"</td>\n",
       "      <td>['grain' 'wheat' 'corn' 'barley' 'oat' 'sorghum']</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"5548\"</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-FEB-1987 15:10:44.60</td>\n",
       "      <td>NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentine grain board figures show\\ncrop regis...</td>\n",
       "      <td>\"NORM\"</td>\n",
       "      <td>['veg-oil' 'linseed' 'lin-oil' 'soy-oil' 'sun-...</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"5549\"</td>\n",
       "      <td>\"6\"</td>\n",
       "      <td>['argentina']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-FEB-1987 15:14:36.41</td>\n",
       "      <td>ARGENTINE 1986/87 GRAIN/OILSEED REGISTRATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moody's Investors Service Inc said it\\nlowered...</td>\n",
       "      <td>\"NORM\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"5551\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-FEB-1987 15:15:40.12</td>\n",
       "      <td>USX &amp;lt;X&gt; DEBT DOWGRADED BY MOODY'S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Champion Products Inc said its\\nboard of direc...</td>\n",
       "      <td>\"NORM\"</td>\n",
       "      <td>['earn']</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"5552\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-FEB-1987 15:17:11.20</td>\n",
       "      <td>CHAMPION PRODUCTS &amp;lt;CH&gt; APPROVES STOCK SPLIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text text_type  \\\n",
       "0  Showers continued throughout the week in\\nthe ...    \"NORM\"   \n",
       "1  The U.S. Agriculture Department\\nreported the ...    \"NORM\"   \n",
       "2  Argentine grain board figures show\\ncrop regis...    \"NORM\"   \n",
       "3  Moody's Investors Service Inc said it\\nlowered...    \"NORM\"   \n",
       "4  Champion Products Inc said its\\nboard of direc...    \"NORM\"   \n",
       "\n",
       "                                              topics lewis_split  \\\n",
       "0                                          ['cocoa']     \"TRAIN\"   \n",
       "1  ['grain' 'wheat' 'corn' 'barley' 'oat' 'sorghum']     \"TRAIN\"   \n",
       "2  ['veg-oil' 'linseed' 'lin-oil' 'soy-oil' 'sun-...     \"TRAIN\"   \n",
       "3                                                 []     \"TRAIN\"   \n",
       "4                                           ['earn']     \"TRAIN\"   \n",
       "\n",
       "       cgis_split  old_id new_id                           places people orgs  \\\n",
       "0  \"TRAINING-SET\"  \"5544\"    \"1\"  ['el-salvador' 'usa' 'uruguay']     []   []   \n",
       "1  \"TRAINING-SET\"  \"5548\"    \"5\"                          ['usa']     []   []   \n",
       "2  \"TRAINING-SET\"  \"5549\"    \"6\"                    ['argentina']     []   []   \n",
       "3  \"TRAINING-SET\"  \"5551\"    \"8\"                          ['usa']     []   []   \n",
       "4  \"TRAINING-SET\"  \"5552\"    \"9\"                          ['usa']     []   []   \n",
       "\n",
       "  exchanges                     date  \\\n",
       "0        []  26-FEB-1987 15:01:01.79   \n",
       "1        []  26-FEB-1987 15:10:44.60   \n",
       "2        []  26-FEB-1987 15:14:36.41   \n",
       "3        []  26-FEB-1987 15:15:40.12   \n",
       "4        []  26-FEB-1987 15:17:11.20   \n",
       "\n",
       "                                              title  \n",
       "0                                BAHIA COCOA REVIEW  \n",
       "1  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE  \n",
       "2     ARGENTINE 1986/87 GRAIN/OILSEED REGISTRATIONS  \n",
       "3              USX &lt;X> DEBT DOWGRADED BY MOODY'S  \n",
       "4    CHAMPION PRODUCTS &lt;CH> APPROVES STOCK SPLIT  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_encoder=False\n",
    "fit_encoder=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define treatment of columns und topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define topics\n",
    "topic_column = 'topics'\n",
    "food = ['coconut', 'cotton-oil', 'sorghum', 'orange', 'rice', 'soybean', 'sun-meal', \n",
    "    'oilseed', 'sugar', 'hog', 'coffee', 'groundnut', 'sunseed', 'sun-oil', 'rye', \n",
    "    'lin-oil', 'copra-cake', 'potato', 'barley', 'tea', 'meal-feed', 'coconut-oil', \n",
    "    'palmkernel', 'cottonseed', 'castor-oil', 'l-cattle', 'livestock', 'soy-oil', \n",
    "    'rape-oil', 'palm-oil', 'cocoa', 'cotton', 'wheat', 'corn', 'f-cattle', 'grain', \n",
    "    'soy-meal', 'oat', 'groundnut-oil', 'veg-oil','rapeseed']\n",
    "resource = ['platinum', 'lead', 'nickel', 'strategic-metal', 'copper', 'palladium', 'gold', \n",
    "    'zinc', 'tin', 'iron-steel', 'alum', 'silver', 'nat-gas', 'rubber', 'pet-chem', 'fuel', 'crude','lumber','propane','wool']\n",
    "finance = ['money-supply', 'dlr', 'nkr', 'lei', 'yen', 'dfl', 'sfr', 'cpi', 'instal-debt', \n",
    "    'money-fx', 'gnp', 'interest', 'income', 'dmk', 'rand', 'bop', 'reserves', 'nzdlr','acq']\n",
    "personal_finance = ['housing','jobs','earn']\n",
    "transport = ['jet', 'ship']\n",
    "topics=[[food,'food'],[resource,'resource'],[finance,'finance'],[personal_finance,'personal_finance'],[transport,'transport']]\n",
    "topics_to_remove = ['gas', 'heat', 'trade', 'retail', 'carcass', 'cpu', 'wpi', 'naphtha', 'ipi','stg','inventories']\n",
    "\n",
    "#columns with special treatment\n",
    "list_column='places'\n",
    "drop_columns=['text_type','people','orgs','exchanges','lewis_split','cgis_split','old_id','new_id']\n",
    "notnan_columns=['text','topics']\n",
    "date_columns=['date']\n",
    "text_columns=['text','title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions for Prepeocessing\n",
    "\n",
    "These may be turned into a library later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row_notnan_columms(df,notnan_columns):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for column in notnan_columns:\n",
    "        df_copy[column].dropna(inplace=True)\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_listcolumns(df, column):\n",
    "    \"\"\"\n",
    "    Wandelt eine Spalte mit Listen als Strings formatiert in echte Listen um und gibt ein DataFrame und die eindeutigen Werte zurück.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Der DataFrame, der die Spalte enthält.\n",
    "    column (str): Der Name der Spalte, die konvertiert werden soll.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Das DataFrame mit der umgewandelten Spalte.\n",
    "    list: Eine Liste der eindeutigen Werte in der umgewandelten Spalte.\n",
    "\n",
    "    Example:\n",
    "    >>> df, unique_values = format_listcolumns(df_train, 'features')\n",
    "    \"\"\"\n",
    "    # Kopie der Spalte erstellen, um die Originaldaten nicht zu ändern\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Umwandlung der Spalte von einem String in eine Liste\n",
    "    df_copy[column].replace({'\\\\n': ''}, regex=True, inplace=True)\n",
    "    df_copy = mytools.df_string_to_list(df_copy, column, entry_delimiter=\"'\", separator=' ')\n",
    "\n",
    "    # Eindeutige Werte in der umgewandelten Spalte finden\n",
    "    unique_values = mytools.df_unique_list_values(df_copy, column)\n",
    "\n",
    "    return df_copy, unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to reorganize a column of subtopics into  broader topics and removing some of them \n",
    "def categorize_topics(df,column,topics,remove):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for topic in topics:\n",
    "        for subtopic in topic[0]:\n",
    "            df_copy[column] = df_copy[column].replace({'\\'' + subtopic + '\\'': '\\'' + topic[1] + '\\''}, regex=True)\n",
    "    \n",
    "    for subtopic in remove:\n",
    "        df_copy[column] = df_copy[column].replace({'\\'' + subtopic + '\\'': ''}, regex=True)\n",
    "    \n",
    "    df_copy[column] = df_copy[column].replace({' ': ''}, regex=True)\n",
    "    df_copy[column] = series_to_list(df_copy, column)\n",
    "    df_copy = df_copy[df_copy[column].str.len() == 1]\n",
    "    df_copy[column] = df_copy[column].apply(lambda x: x[0])\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_datecolumns(df,date_columns):\n",
    "    # Kopie des DataFrame erstellen, um die Originaldaten nicht zu ändern\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for column in date_columns:\n",
    "        # Die Zeichenkette in ein Datum konvertieren\n",
    "        df_copy[column] = pd.to_datetime(df_copy[column].str.strip().str.split(' ').str.get(0))\n",
    "        df_copy[column+'_month'] = df_copy[column].dt.month\n",
    "\n",
    "        # Woche extrahieren (altes Verhalten, ab Pandas 1.1.0 ist isocalendar().week empfohlen)\n",
    "        df_copy[column+'_day_month'] = df_copy[column].dt.day\n",
    "\n",
    "        # Tag extrahieren\n",
    "        df_copy[column+'_day_year'] = df_copy[column].dt.day_of_year\n",
    "\n",
    "        # Wochentag extrahieren (Montag=0, Sonntag=6)\n",
    "        df_copy[column+'_weekday'] = df_copy[column].dt.day_name('en')\n",
    "\n",
    "        df_copy[column+'_quarter_year'] = df_copy[column].dt.quarter\n",
    "        df_copy = pd.get_dummies(df_copy, columns=[column+'_weekday'])\n",
    "        weekdays = ['weekday_Monday', 'weekday_Tuesday', 'weekday_Wednesday', 'weekday_Thursday', 'weekday_Friday', 'weekday_Saturday', 'weekday_Sunday']\n",
    "        for weekday in weekdays:\n",
    "            if not column+'_'+weekday in df_copy.columns:\n",
    "                df_copy[column+'_'+weekday] = 0\n",
    "            else:\n",
    "                df_copy[column+'_'+weekday] = df_copy[column+'_'+weekday].astype(int)\n",
    "\n",
    "        df_copy = df_copy.drop(columns=column)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\1029708371.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_copy[column] = df_copy[column].str.replace('\\s+', ' ', regex=True)\n"
     ]
    }
   ],
   "source": [
    "def format_textcolumns(df,text_columns):\n",
    "    # Kopie des DataFrame erstellen, um die Originaldaten nicht zu ändern\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for column in text_columns:\n",
    "        df_copy[column].replace({'&lt;': '<'}, regex=True, inplace=True)\n",
    "        df_copy[column].replace({'\\\\n': ' '}, regex=True, inplace=True)\n",
    "        df_copy[column] = df_copy[column].str.replace('\\s+', ' ', regex=True)\n",
    "        df_copy[column] = df_copy[column].str.lower()\n",
    "        df_copy[column] = df_copy[column].fillna(value='')\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_special_columns(df,list_column,list_possible_values,drop_columns,date_columns,notnan_columns,text_columns):\n",
    "    # Kopie des DataFrame erstellen, um die Originaldaten nicht zu ändern\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Spalten aus dem DataFrame entfernen\n",
    "    df_copy = df_copy.drop(columns=drop_columns)\n",
    "\n",
    "    # Spalte mit Listen explodieren und mögliche Werte festlegen\n",
    "    df_copy = mytools.df_explode_listcolumn(df_copy, list_column, list_possible_values)\n",
    "\n",
    "    # Datumsangaben formatieren\n",
    "    df_copy = format_datecolumns(df_copy, date_columns)\n",
    "\n",
    "    # Zeilen entfernen, die NaN-Werte in bestimmten Spalten enthalten\n",
    "    df_copy = drop_row_notnan_columms(df_copy, notnan_columns)\n",
    "\n",
    "    # Textspalten formatieren\n",
    "    df_copy = format_textcolumns(df_copy, text_columns)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#has to expanded to make it readeble by model\n",
    "def preprocessing(df,topic_column,topics,topics_to_remove,list_column,list_possible_values,drop_columns,date_columns,notnan_columns,text_columns,encoder,fit_encoder=True):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy = categorize_topics(df_copy, topic_column, topics, topics_to_remove)\n",
    "    df_copy = handle_special_columns(df_copy, list_column, list_possible_values, drop_columns, date_columns, notnan_columns, text_columns)\n",
    "    \n",
    "    additional_features = df_copy.drop(columns=(text_columns + [topic_column]))\n",
    "    \n",
    "    if fit_encoder:\n",
    "        labels = torch.tensor(encoder.fit_transform(df_copy[topic_column]))\n",
    "    else:\n",
    "        labels = torch.tensor(encoder.transform(df_copy[topic_column]))\n",
    "    labels = labels.long()\n",
    "    \n",
    "    return df_copy[text_columns], additional_features, labels, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\2357064120.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy[column].replace({'\\\\n': ''}, regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df,unique_values_test = format_listcolumns(df_test,list_column)\n",
    "df,unique_values_train = format_listcolumns(df_train,list_column)\n",
    "unique_countries=unique_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_encoder:\n",
    "    label_encoder = joblib.load('label_encoder.joblib')\n",
    "else:\n",
    "   label_encoder = LabelEncoder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\3411280864.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_copy[column] = pd.to_datetime(df_copy[column].str.strip().str.split(' ').str.get(0))\n",
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\1029708371.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy[column].replace({'&lt;': '<'}, regex=True, inplace=True)\n",
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\3411280864.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_copy[column] = pd.to_datetime(df_copy[column].str.strip().str.split(' ').str.get(0))\n",
      "C:\\Users\\tilll\\AppData\\Local\\Temp\\ipykernel_30244\\1029708371.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy[column].replace({'&lt;': '<'}, regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df_text,train_additional_features,train_labels,label_encoder = preprocessing(df_train,topic_column,topics,topics_to_remove,list_column,unique_countries,drop_columns,date_columns,notnan_columns,text_columns,label_encoder,fit_encoder=fit_encoder)\n",
    "\n",
    "test_df_text,test_additional_features,test_labels,label_encoder = preprocessing(df_test,topic_column,topics,topics_to_remove,list_column,unique_countries,drop_columns,date_columns,notnan_columns,text_columns,label_encoder,fit_encoder=fit_encoder)\n",
    "\n",
    "if not load_encoder:\n",
    "    joblib.dump(label_encoder, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score-Encoder erstellen\n",
    "fit_encoder = False\n",
    "zscore_encoder = mytools.ZScoreEncoder()\n",
    "standardize_columns = ['date_month', 'date_day_month', 'date_day_year', 'date_quarter_year']\n",
    "\n",
    "if fit_encoder:\n",
    "    train_additional_features = zscore_encoder.fit_transform(train_additional_features, standardize_columns)\n",
    "else:\n",
    "    zscore_encoder.load('zscore_encoder.joblib')\n",
    "    train_additional_features = zscore_encoder.transform(train_additional_features)\n",
    "\n",
    "test_additional_features = zscore_encoder.transform(test_additional_features)\n",
    "\n",
    "# Z-Score-Encoder speichern\n",
    "if fit_encoder:\n",
    "    zscore_encoder.save('zscore_encoder.joblib')\n",
    "\n",
    "#convert additional features to tensor\n",
    "train_additional_features = torch.tensor(train_additional_features.values).float()\n",
    "test_additional_features = torch.tensor(test_additional_features.values).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellung des Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definieren der Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='bert-base-multilingual-uncased'\n",
    "num_additional_features=139\n",
    "num_classes=5\n",
    "freeze_bert=True\n",
    "num_epochs=5\n",
    "batch_size=32\n",
    "model_path_base='models/Bert_freeze_extended'\n",
    "train_epochs=5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initilisieren vom Tokennizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definieren der benötigten Funktionen und Objekte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizen und Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(text,length=128):\n",
    "    tokenized_text = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=length)\n",
    "    return tokenized_text\n",
    "\n",
    "def tokenize_inputs(df_text):\n",
    "    tokenized_inputs1 = []\n",
    "    tokenized_inputs2 = []\n",
    "    for idx, row in df_text.iterrows():\n",
    "        inputs1 = tokenize_texts(row['text'],256)\n",
    "        inputs2 = tokenize_texts(row['title'],16)\n",
    "        tokenized_inputs1.append(inputs1)\n",
    "        tokenized_inputs2.append(inputs2)\n",
    "    return tokenized_inputs1,tokenized_inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Text_Feature_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_inputs1, tokenized_inputs2, additional_features, labels):\n",
    "        self.tokenized_inputs1 = tokenized_inputs1\n",
    "        self.tokenized_inputs2 = tokenized_inputs2\n",
    "        self.additional_features = additional_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids1 = self.tokenized_inputs1[idx]['input_ids'].squeeze()\n",
    "        attention_mask1 = self.tokenized_inputs1[idx]['attention_mask'].squeeze()\n",
    "        input_ids2 = self.tokenized_inputs2[idx]['input_ids'].squeeze()\n",
    "        attention_mask2 = self.tokenized_inputs2[idx]['attention_mask'].squeeze()\n",
    "        additional_features = self.additional_features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-multilingual-uncased', num_additional_features=119, num_classes=5, freeze_bert=True,hidden_layers=None):\n",
    "        super(MultilingualBERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        \n",
    "        # Einfrieren der BERT-Gewichte, falls angegeben\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.additional_features_layers = nn.Sequential(\n",
    "            nn.Linear(num_additional_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Anzahl der Neuronen im Input-Layer des Klassifikators (BERT Output * 2 + zusätzliche Features)\n",
    "        input_size = 768 * 2 + 128\n",
    "\n",
    "        # Erstellen der Hidden Layers\n",
    "        if hidden_layers is None:\n",
    "            hidden_layers = []\n",
    "        layers = []\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.1))\n",
    "            input_size = hidden_size\n",
    "\n",
    "        # Finaler Klassifikations-Layer\n",
    "        layers.append(nn.Linear(input_size, num_classes))\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "        \n",
    "        # Speichern der Initialisierungsparameter\n",
    "        self.init_params = {\n",
    "            'bert_model_name': bert_model_name,\n",
    "            'num_additional_features': num_additional_features,\n",
    "            'num_classes': num_classes,\n",
    "            'freeze_bert': freeze_bert,\n",
    "            'hidden_layers': hidden_layers\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features):\n",
    "        outputs1 = self.bert(input_ids1, attention_mask=attention_mask1)\n",
    "        pooled_output1 = outputs1[1]  # [CLS] token representation\n",
    "        \n",
    "        outputs2 = self.bert(input_ids2, attention_mask=attention_mask2)\n",
    "        pooled_output2 = outputs2[1]  # [CLS] token representation\n",
    "        \n",
    "        additional_features_output = self.additional_features_layers(additional_features)\n",
    "        \n",
    "        combined_output = torch.cat((pooled_output1, pooled_output2, additional_features_output), dim=1)\n",
    "        combined_output = self.dropout(combined_output)\n",
    "        \n",
    "        logits = self.classifier(combined_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_append_metrics(epoch, classes, labels, predictions,df=None):\n",
    "    # Confusion Matrix erstellen \n",
    "    cm = confusion_matrix(labels, predictions, labels=classes)\n",
    "    # Spalten für das DataFrame definieren\n",
    "    columns = ['Epoch', 'Class', 'TP abs', 'True Positive', 'TP %', 'FP abs', 'False Positive', 'FP %', 'FN abs','False Negative', 'FN %']\n",
    "    data = []\n",
    "\n",
    "    # Iteration über die Klassen\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        total = sum(1 for label in labels if label == class_name)\n",
    "        true_positive = cm[idx, idx]\n",
    "        false_positive = cm[:, idx].sum() - true_positive\n",
    "        false_negative = cm[idx,:].sum() - true_positive\n",
    "\n",
    "        tp_percent = (true_positive / total) * 100 if total > 0 else 0\n",
    "        fp_percent = (false_positive / total) * 100 if total > 0 else 0\n",
    "        fn_percent = (false_negative / total) * 100 if total > 0 else 0\n",
    "\n",
    "        tp_text = f\"{round(tp_percent,2)}% ({true_positive})\"\n",
    "        fp_text = f\"{round(fp_percent,2)}% ({false_positive})\"\n",
    "        fn_text = f\"{round(fn_percent,2)}% ({false_negative})\"\n",
    "\n",
    "\n",
    "        data.append([epoch, class_name, true_positive, tp_text, tp_percent, false_positive, fp_text, fp_percent, false_negative, fn_text, fn_percent])\n",
    "\n",
    "    # DataFrame für die aktuelle Epoche erstellen\n",
    "    epoch_df = pd.DataFrame(data, columns=columns)\n",
    "    epoch_df.set_index(['Epoch', 'Class'],inplace=True)\n",
    "    if df is None:\n",
    "        return epoch_df\n",
    "    else:\n",
    "        return pd.concat([df, epoch_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scheduler, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in tqdm(dataloader, desc=f'Epoch {epoch + 1}'):\n",
    "            input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features, labels = batch\n",
    "            input_ids1, attention_mask1 = input_ids1.to(device), attention_mask1.to(device)\n",
    "            input_ids2, attention_mask2 = input_ids2.to(device), attention_mask2.to(device)\n",
    "            additional_features, labels = additional_features.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Vorwärtsdurchlauf\n",
    "            logits = model(input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features)\n",
    "\n",
    "            # Verlust berechnen\n",
    "            loss = criterion(logits, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Rückwärtsdurchlauf und Optimierung\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} (BERT eingefroren), Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,counter,test_dataset,df=None):    \n",
    "    #test modell\n",
    "    model.eval()\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features, labels = batch\n",
    "            input_ids1, attention_mask1 = input_ids1.to(device), attention_mask1.to(device)\n",
    "            input_ids2, attention_mask2 = input_ids2.to(device), attention_mask2.to(device)\n",
    "            additional_features, labels = additional_features.to(device), labels.to(device)\n",
    "\n",
    "            logits = model(input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            test_predictions.extend(predictions.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_predictions = label_encoder.inverse_transform(test_predictions)\n",
    "    test_labels = label_encoder.inverse_transform(test_labels)\n",
    "\n",
    "    accuracy = sum(test_predictions == test_labels) / len(test_labels)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    classes=[topic[1] for topic in topics] \n",
    "    if counter==1:\n",
    "        df=calculate_and_append_metrics(counter, classes, test_labels, test_predictions)\n",
    "    else:\n",
    "        df=calculate_and_append_metrics(counter, classes, test_labels, test_predictions,df)\n",
    "    counter+=1\n",
    "\n",
    "    \n",
    "    return df,counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen des Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Text\n",
    "train_tokenized_inputs1, train_tokenized_inputs2= tokenize_inputs(train_df_text)\n",
    "test_tokenized_inputs1, test_tokenized_inputs2= tokenize_inputs(test_df_text)\n",
    "#Create Datasets\n",
    "train_dataset = Text_Text_Feature_Dataset(train_tokenized_inputs1, train_tokenized_inputs2,train_additional_features,train_labels)\n",
    "test_dataset = Text_Text_Feature_Dataset(test_tokenized_inputs1, test_tokenized_inputs2,test_additional_features,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisieren von Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a valid mode\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:540\u001b[0m, in \u001b[0;36m_check_seekable\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(f\u001b[38;5;241m.\u001b[39mtell())\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create or load model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmytools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelversions_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mversions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel_path_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path_base\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# If no model was loaded, initialize a new one\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m MultilingualBERTClassifier(num_additional_features\u001b[38;5;241m=\u001b[39mnum_additional_features, num_classes\u001b[38;5;241m=\u001b[39mnum_classes,hidden_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m])\n",
      "File \u001b[1;32mc:\\Projects\\Reuters\\My_Machine_Learning_Tools.py:599\u001b[0m, in \u001b[0;36mmodelversions_load_model\u001b[1;34m(mode, model_path_base, version, path)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03mLädt ein Modell aus einer bestimmten Version oder einem angegebenen Pfad basierend auf dem Modus.\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03mModel loaded from /path/to/models/model_v2.pt\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m model_path \u001b[38;5;241m=\u001b[39m _modelversions_get_loadpath(mode,model_path_base,version,path)\n\u001b[1;32m--> 599\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m model_class \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    601\u001b[0m model_init_params \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_init_params\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_buffer_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in mode but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:434\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(buffer)\n\u001b[1;32m--> 434\u001b[0m     \u001b[43m_check_seekable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:543\u001b[0m, in \u001b[0;36m_check_seekable\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (io\u001b[38;5;241m.\u001b[39mUnsupportedOperation, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 543\u001b[0m     \u001b[43mraise_err_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseek\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:536\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[1;34m(patterns, e)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[0;32m    533\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m try to load from it instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 536\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "# Create or load model\n",
    "model = mytools.modelversions_load_model('versions',model_path_base=model_path_base)\n",
    "if model is None:\n",
    "    # If no model was loaded, initialize a new one\n",
    "    model = MultilingualBERTClassifier(num_additional_features=num_additional_features, num_classes=num_classes,hidden_layers=[256, 128])\n",
    "    print('New model created.')\n",
    "else:\n",
    "    print('Model loaded from saved version.')\n",
    "\n",
    "# Move model to device if possible\n",
    "model.to(device)\n",
    "print('Model on device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilll\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "#create Dataloader\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Loss-Funktion and Optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=mytools.train_calculate_class_weights(train_labels).to(device))\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/199 [00:00<?, ?it/s]C:\\Users\\tilll\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epoch 1: 100%|██████████| 199/199 [01:04<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6543200727383695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6505842026154599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:02<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6426092100203337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:02<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6353980485518375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6467912054091842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:23<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8679169992019155\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "1     True Positive    95.1% (931)  72.44% (92)     88.98% (977)   \n",
      "      False Positive  21.45% (210)  15.75% (20)       1.18% (13)   \n",
      "      False Negative     4.9% (48)  27.56% (35)     11.02% (121)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "1     True Positive   60.75% (161)  37.84% (14)  \n",
      "      False Positive   29.06% (77)  29.73% (11)  \n",
      "      False Negative  39.25% (104)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:02<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6502617236657359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:02<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6616080424294399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6429676259282845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:02<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6534104857912015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6352182605757786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:24<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8679169992019155\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "1     True Positive    95.1% (931)  72.44% (92)     88.98% (977)   \n",
      "      False Positive  21.45% (210)  15.75% (20)       1.18% (13)   \n",
      "      False Negative     4.9% (48)  27.56% (35)     11.02% (121)   \n",
      "2     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.27% (218)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "1     True Positive   60.75% (161)  37.84% (14)  \n",
      "      False Positive   29.06% (77)  29.73% (11)  \n",
      "      False Negative  39.25% (104)  62.16% (23)  \n",
      "2     True Positive   58.11% (154)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.89% (111)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6379222865380234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6457628454245514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6390728999921425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6345920788882365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:02<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6360997734357364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:23<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "1     True Positive    95.1% (931)  72.44% (92)     88.98% (977)   \n",
      "      False Positive  21.45% (210)  15.75% (20)       1.18% (13)   \n",
      "      False Negative     4.9% (48)  27.56% (35)     11.02% (121)   \n",
      "2     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.27% (218)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "3     True Positive   95.51% (935)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.49% (44)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "1     True Positive   60.75% (161)  37.84% (14)  \n",
      "      False Positive   29.06% (77)  29.73% (11)  \n",
      "      False Negative  39.25% (104)  62.16% (23)  \n",
      "2     True Positive   58.11% (154)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.89% (111)  62.16% (23)  \n",
      "3     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  29.73% (11)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6430941020424042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:02<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6344589149233085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:02<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6309044257779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:07<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.643410467921789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:08<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6318859750002472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:26<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8691141260973663\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "2     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.27% (218)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "3     True Positive   95.51% (935)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.49% (44)  23.62% (30)     11.29% (124)   \n",
      "4     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "2     True Positive   58.11% (154)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.89% (111)  62.16% (23)  \n",
      "3     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  29.73% (11)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n",
      "4     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.629021381912519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:10<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6556686338168293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:11<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6519219963694337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:06<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6325551864489838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:04<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.639870788434043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "3     True Positive   95.51% (935)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.49% (44)  23.62% (30)     11.29% (124)   \n",
      "4     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "5     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "3     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  29.73% (11)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n",
      "4     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n",
      "5     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:00<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6272536741578998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [00:58<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6436543403258875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [00:57<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6510419020401174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [00:58<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6535074358908974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [00:58<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6379132073129242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:22<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8683160415003991\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "4     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  21.96% (215)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "5     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "6     True Positive   95.61% (936)  75.59% (96)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  24.41% (31)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "4     True Positive   59.25% (157)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  40.75% (108)  62.16% (23)  \n",
      "5     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "6     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.42% (70)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6471542807380158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:02<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6298495531082153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [00:57<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6442830993901545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:01<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.658505396777062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:06<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6392943933980548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:22<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "5     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "6     True Positive   95.61% (936)  75.59% (96)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  24.41% (31)     11.29% (124)   \n",
      "7     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "5     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "6     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.42% (70)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "7     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6332010419374734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6429791585284861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6348020167806041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6500801274824382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6292990821989337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:23<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "6     True Positive   95.61% (936)  75.59% (96)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  24.41% (31)     11.29% (124)   \n",
      "7     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "8     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "6     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.42% (70)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "7     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "8     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.6568559075719748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.6472624116507008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6317494337882229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.640109765319968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6425751170620846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:26<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n",
      "Class                      finance         food personal_finance  \\\n",
      "Epoch                                                              \n",
      "7     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "8     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "9     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
      "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
      "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
      "\n",
      "Class                     resource    transport  \n",
      "Epoch                                            \n",
      "7     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "8     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n",
      "9     True Positive   58.87% (156)  37.84% (14)  \n",
      "      False Positive   26.04% (69)  27.03% (10)  \n",
      "      False Negative  41.13% (109)  62.16% (23)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 199/199 [01:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (BERT eingefroren), Loss: 0.650379529550447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 199/199 [01:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 (BERT eingefroren), Loss: 0.635593610492783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 (BERT eingefroren), Loss: 0.6280244075173709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 199/199 [01:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 (BERT eingefroren), Loss: 0.6400275985200201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 199/199 [01:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 (BERT eingefroren), Loss: 0.6312347738886598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:23<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687150837988827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>finance</th>\n",
       "      <th>food</th>\n",
       "      <th>personal_finance</th>\n",
       "      <th>resource</th>\n",
       "      <th>transport</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Class                      finance         food personal_finance  \\\n",
       "Epoch                                                              \n",
       "7     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "8     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "9     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "\n",
       "Class                     resource    transport  \n",
       "Epoch                                            \n",
       "7     True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  \n",
       "8     True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  \n",
       "9     True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(train_epochs):\n",
    "    if i>0:\n",
    "        metrics_df = df.loc[df.index.get_level_values('Epoch') >= (df.index.get_level_values('Epoch').max() - 2)] \n",
    "        columns = pd.MultiIndex.from_product([metrics_df.columns.get_level_values(0).unique(), ['True Positive', 'False Positive', 'False Negative']]) \n",
    "        metrics_table = pd.DataFrame(index=metrics_df.index.levels[0], columns=columns) \n",
    "        metrics_df = metrics_df[['True Positive','False Positive','False Negative']] \n",
    "        metrics_df = metrics_df.stack().unstack(1)\n",
    "        print(metrics_df)\n",
    "    train(model, dataloader, criterion, optimizer, scheduler, num_epochs)\n",
    "    if i==0:\n",
    "        df,counter=eval(model,counter)\n",
    "    else:\n",
    "        df,counter=eval(model,counter,df)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>finance</th>\n",
       "      <th>food</th>\n",
       "      <th>personal_finance</th>\n",
       "      <th>resource</th>\n",
       "      <th>transport</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>True Positive</th>\n",
       "      <td>95.61% (936)</td>\n",
       "      <td>76.38% (97)</td>\n",
       "      <td>88.71% (974)</td>\n",
       "      <td>58.87% (156)</td>\n",
       "      <td>37.84% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>22.06% (216)</td>\n",
       "      <td>17.32% (22)</td>\n",
       "      <td>1.09% (12)</td>\n",
       "      <td>26.04% (69)</td>\n",
       "      <td>27.03% (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>4.39% (43)</td>\n",
       "      <td>23.62% (30)</td>\n",
       "      <td>11.29% (124)</td>\n",
       "      <td>41.13% (109)</td>\n",
       "      <td>62.16% (23)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Class                      finance         food personal_finance  \\\n",
       "Epoch                                                              \n",
       "8     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "9     True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "10    True Positive   95.61% (936)  76.38% (97)     88.71% (974)   \n",
       "      False Positive  22.06% (216)  17.32% (22)       1.09% (12)   \n",
       "      False Negative    4.39% (43)  23.62% (30)     11.29% (124)   \n",
       "\n",
       "Class                     resource    transport  \n",
       "Epoch                                            \n",
       "8     True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  \n",
       "9     True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  \n",
       "10    True Positive   58.87% (156)  37.84% (14)  \n",
       "      False Positive   26.04% (69)  27.03% (10)  \n",
       "      False Negative  41.13% (109)  62.16% (23)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = df.loc[df.index.get_level_values('Epoch') >= (df.index.get_level_values('Epoch').max() - 2)] \n",
    "columns = pd.MultiIndex.from_product([metrics_df.columns.get_level_values(0).unique(), ['True Positive', 'False Positive', 'False Negative']]) \n",
    "metrics_table = pd.DataFrame(index=metrics_df.index.levels[0], columns=columns) \n",
    "metrics_df = metrics_df[['True Positive','False Positive','False Negative']] \n",
    "metrics_df.stack().unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:23<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sichere Vorhersagen Accuracy: 0.9617\n",
      "Unsichere Vorhersagen Accuracy: 0.5908\n",
      "Anzahl sichere Vorhersagen: 1878\n",
      "Anzahl unsichere Vorhersagen: 628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Modell in den Evaluationsmodus setzen\n",
    "model.eval()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "probabilities = torch.empty(0, num_classes)\n",
    "predictions = torch.empty(0)\n",
    "max_probabilities = torch.empty(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features, labels = batch\n",
    "        input_ids1, attention_mask1 = input_ids1.to(device), attention_mask1.to(device)\n",
    "        input_ids2, attention_mask2 = input_ids2.to(device), attention_mask2.to(device)\n",
    "        additional_features, labels = additional_features.to(device), labels.to(device)\n",
    "\n",
    "        batch_logits = model(input_ids1, attention_mask1, input_ids2, attention_mask2, additional_features)\n",
    "        #shift to cpu\n",
    "        batch_probabilities = F.softmax(batch_logits, dim=1).cpu()\n",
    "        batch_predictions = torch.argmax(batch_logits, dim=1).cpu()\n",
    "        batch_max_probabilities = torch.max(batch_probabilities, dim=1).values\n",
    "\n",
    "        probabilities = torch.cat((probabilities, batch_probabilities), dim=0)\n",
    "        predictions = torch.cat((predictions, batch_predictions), dim=0)\n",
    "        max_probabilities = torch.cat((max_probabilities, batch_max_probabilities), dim=0)\n",
    "\n",
    "# Schwellenwert definieren\n",
    "threshold = 0.7\n",
    "\n",
    "# Sichere und unsichere Vorhersagen unterscheiden\n",
    "secure_predictions = max_probabilities >= threshold\n",
    "insecure_predictions = max_probabilities < threshold\n",
    "\n",
    "# Ausgabe der sicheren und unsicheren Vorhersagen\n",
    "secure_results = predictions[secure_predictions]\n",
    "insecure_results = predictions[insecure_predictions]\n",
    "\n",
    "# True Labels für beide Gruppen\n",
    "secure_labels = test_labels[secure_predictions]\n",
    "insecure_labels = test_labels[insecure_predictions]\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Accuracy für sichere Vorhersagen\n",
    "if secure_labels.size(0) > 0:\n",
    "    secure_accuracy = calculate_accuracy(secure_results, secure_labels)\n",
    "else:\n",
    "    secure_accuracy = 0  # Keine sicheren Vorhersagen\n",
    "\n",
    "# Accuracy für unsichere Vorhersagen\n",
    "if insecure_labels.size(0) > 0:\n",
    "    insecure_accuracy = calculate_accuracy(insecure_results, insecure_labels)\n",
    "else:\n",
    "    insecure_accuracy = 0  # Keine unsicheren Vorhersagen\n",
    "\n",
    "# Ausgabe der Accuracy für beide Gruppen\n",
    "print(f'Sichere Vorhersagen Accuracy: {secure_accuracy:.4f}')\n",
    "print(f'Unsichere Vorhersagen Accuracy: {insecure_accuracy:.4f}')\n",
    "\n",
    "#anzahl der sicheren und unsicheren vorhersagen\n",
    "num_secure = secure_labels.size(0)\n",
    "num_insecure = insecure_labels.size(0)\n",
    "\n",
    "# Ausgabe der Anzahl der sicheren und unsicheren Vorhersagen\n",
    "print(f'Anzahl sichere Vorhersagen: {num_secure}')\n",
    "print(f'Anzahl unsichere Vorhersagen: {num_insecure}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/Bert_freeze_extended_v2.pt\n"
     ]
    }
   ],
   "source": [
    "mytools.modelversions_save_model(model, model_path_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
